import asyncio
import json
from langchain_core.messages import HumanMessage


async def run_chat_stream(agent_graph, user_input: str, user_id: str = "default_user"):
    """
    é€šç”¨çš„ Agent æµå¼è¿è¡Œå™¨ã€‚
    è´Ÿè´£å°† Agent çš„æ€è€ƒè¿‡ç¨‹å’Œç»“æœæ¼‚äº®åœ°æ‰“å°åˆ°æ§åˆ¶å°ã€‚

    Args:
        agent_graph: ç¼–è¯‘å¥½çš„ LangGraph å¯¹è±¡
        user_input: ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬
        user_id: çº¿ç¨‹ IDï¼Œç”¨äºè®°å¿†åŠŸèƒ½
    """
    print(f"\nğŸ”µ ç”¨æˆ·({user_id}): {user_input}")
    print("ğŸŸ¢ Agent: ", end="", flush=True)

    # æ„é€ è¾“å…¥
    inputs = {
        "messages": [HumanMessage(content=user_input)],
        # user_id ä¸éœ€è¦ä¼ å…¥ stateï¼Œè€Œæ˜¯ä½œä¸º thread_id ä¼ å…¥ config
    }

    config = {"configurable": {"thread_id": user_id}}

    # Nodes that return static messages or messages not generated by a streaming LLM in the final step
    # These nodes construct AIMessage manually, so we need to capture their output at on_chain_end
    STATIC_MESSAGE_NODES = {
        "search_flight",
        "select_flight",
        "pay_flight",
        "search_hotel",
        "select_hotel",
        "pay_hotel",
        "summary",
        "check_weather",
        "side_chat"
    }

    try:
        # ä½¿ç”¨ astream_events v2 API è·å–ç»†ç²’åº¦çš„æµå¼äº‹ä»¶
        async for event in agent_graph.astream_events(inputs, version="v2", config=config):
            kind = event["event"]

            # 1. æ•è· LLM çš„æ–‡æœ¬æµ (on_chat_model_stream)
            # è¿™æ˜¯ LLM ç”Ÿæˆå›å¤çš„è¿‡ç¨‹
            if kind == "on_chat_model_stream":
                chunk = event["data"]["chunk"]
                if hasattr(chunk, "content") and chunk.content:
                    print(chunk.content, end="", flush=True)

            # 2. æ•è·å·¥å…·è°ƒç”¨å¼€å§‹ (on_tool_start)
            # ç”¨äºæ˜¾ç¤ºç³»ç»Ÿæ­£åœ¨åšä»€ä¹ˆï¼Œå¢åŠ äº¤äº’æ„Ÿ
            elif kind == "on_tool_start":
                print(
                    f"\n   âš™ï¸  [ç³»ç»Ÿè°ƒç”¨å·¥å…·]: {event['name']} ... ", end="", flush=True)

            # 3. æ•è·å·¥å…·è°ƒç”¨ç»“æŸ (on_tool_end)
            elif kind == "on_tool_end":
                print("å®Œæˆã€‚", end="\nğŸŸ¢ Agent: ", flush=True)

            # 4. Capture output from nodes that don't stream via LLM
            elif kind == "on_chain_end":
                node_name = event["name"]
                if node_name in STATIC_MESSAGE_NODES:
                    output = event["data"].get("output")
                    if output and isinstance(output, dict) and "messages" in output:
                        messages = output["messages"]
                        if messages:
                            last_msg = messages[-1]
                            content = last_msg.content if hasattr(
                                last_msg, "content") else last_msg.get("content")
                            if content:
                                print(content, end="", flush=True)

    except Exception as e:
        print(f"\nâŒ è¿è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")

    print("\n" + "-" * 60)


async def sse_chat_stream(agent_graph, input_payload: dict, config: dict):
    """
    SSE (Server-Sent Events) ç”Ÿæˆå™¨ã€‚
    å®ç°äº†æ˜ç¡®çš„å‰åç«¯é€šä¿¡åè®® (Protocol Adapter)ã€‚

    Protocol Definition:
    - event: message  -> èŠå¤©æ°”æ³¡æ–‡æœ¬ (data: {content: "...", is_stream: bool})
    - event: control  -> å‰ç«¯äº¤äº’ç»„ä»¶ (data: {type: "select_plan", options: [...]})
    - event: status   -> çŠ¶æ€/Loadingæç¤º (data: {content: "..."})
    - event: error    -> é”™è¯¯ä¿¡æ¯ (data: {message: "..."})
    """

    # --- è¾…åŠ©å‡½æ•°: ç»Ÿä¸€ SSE æ ¼å¼ ---
    def create_event(event_type: str, payload: dict):
        # ensure_ascii=False ç¡®ä¿ä¸­æ–‡ä¸è¢«è½¬ä¹‰ä¸º \uXXXX
        return f"event: {event_type}\ndata: {json.dumps(payload, ensure_ascii=False)}\n\n"

    # --- é…ç½®: å…è®¸æµå¼è¾“å‡ºæ–‡æœ¬çš„èŠ‚ç‚¹ ---
    # è¿™äº›èŠ‚ç‚¹çš„ LLM è¾“å‡ºæ˜¯çº¯æ–‡æœ¬ï¼Œé€‚åˆç›´æ¥æ‰“å­—æœºå±•ç¤º
    # æ³¨æ„: å¦‚æœèŠ‚ç‚¹ä½¿ç”¨ invoke/ainvoke è€Œé streamï¼Œåˆ™ä¸ä¼šè§¦å‘ on_chat_model_stream
    # ä¸ºäº†ç¨³å®šæ€§ï¼Œæš‚æ—¶å…³é—­æµå¼ï¼Œç»Ÿä¸€ä½¿ç”¨ on_chain_end è¾“å‡º
    ALLOW_STREAMING_NODES = set() 

    try:
        # ç›‘å¬ LangGraph çš„ç»†ç²’åº¦äº‹ä»¶
        async for event in agent_graph.astream_events(input_payload, version="v2", config=config):
            kind = event["event"]
            node_name = event.get("name", "")

            # --- 1. çŠ¶æ€åé¦ˆ (Status Feedback) ---
            # ç›®çš„: ç¼“è§£ç”¨æˆ·ç­‰å¾…ç„¦è™‘ï¼Œæ˜¾ç¤ºç³»ç»Ÿå½“å‰åŠ¨ä½œ
            if kind == "on_chain_start":
                if node_name in ["collect", "plan", "search_flight", "search_hotel"]:
                    yield create_event("status", {"content": "ğŸ¤” æ­£åœ¨æ€è€ƒ...", "node": node_name})

            elif kind == "on_tool_start" and not node_name.startswith("_"):
                yield create_event("status", {"content": f"âš™ï¸ è°ƒç”¨å·¥å…·: {node_name}...", "node": node_name})

            # --- 2. å®æ—¶æ–‡æœ¬æµ (Real-time Text Streaming) ---
            # ç›®çš„: æä¾›æ‰“å­—æœºæ•ˆæœã€‚ä»…å¯¹ç™½åå•èŠ‚ç‚¹å¼€æ”¾ï¼Œé˜²æ­¢ JSON æºç æ³„éœ²ã€‚
            elif kind == "on_chat_model_stream":
                if node_name in ALLOW_STREAMING_NODES:
                    chunk = event["data"]["chunk"]
                    if hasattr(chunk, "content") and chunk.content:
                        yield create_event("message", {"content": chunk.content, "is_stream": True})

            # --- 3. èŠ‚ç‚¹ç»“æœå¤„ç† (Node Result Processing) ---
            # ç›®çš„: èŠ‚ç‚¹æ‰§è¡Œç»“æŸåï¼Œæ ¹æ®èŠ‚ç‚¹ç±»å‹ï¼Œå†³å®šå‘é€ä»€ä¹ˆç»“æ„åŒ–æ•°æ®ç»™å‰ç«¯
            elif kind == "on_chain_end":
                output = event["data"].get("output")
                if not output or not isinstance(output, dict):
                    continue

                # === ç­–ç•¥ A: æ–¹æ¡ˆç”ŸæˆèŠ‚ç‚¹ ===
                if node_name == "plan":
                    # 1. å‘é€äº¤äº’æŒ‡ä»¤: å¼¹å‡ºæ–¹æ¡ˆé€‰æ‹©å¡ç‰‡
                    plans = output.get("generated_plans", [])
                    if plans:
                        yield create_event("control", {"type": "select_plan", "options": plans})
                    # 2. å‘é€æ–‡æœ¬å›å¤
                    if msgs := output.get("messages"):
                        yield create_event("message", {"content": msgs[-1].content, "is_stream": False})

                # === ç­–ç•¥ B: æœºç¥¨æœç´¢èŠ‚ç‚¹ ===
                elif node_name == "search_flight":
                    options = output.get(
                        "realtime_options", {}).get("flights", [])
                    if isinstance(options, list) and options and "error" not in options[0]:
                        yield create_event("control", {"type": "select_flight", "options": options})
                    if msgs := output.get("messages"):
                        yield create_event("message", {"content": msgs[-1].content, "is_stream": False})

                # === ç­–ç•¥ C: é…’åº—æœç´¢èŠ‚ç‚¹ ===
                elif node_name == "search_hotel":
                    options = output.get(
                        "realtime_options", {}).get("hotels", [])
                    if isinstance(options, list) and options and "error" not in options[0]:
                        yield create_event("control", {"type": "select_hotel", "options": options})
                    if msgs := output.get("messages"):
                        yield create_event("message", {"content": msgs[-1].content, "is_stream": False})

                # === ç­–ç•¥ D: æ™®é€šæ–‡æœ¬èŠ‚ç‚¹ (Collect, Pay, Weather, Summary, SideChat) ===
                # è¿™äº›èŠ‚ç‚¹é€šå¸¸è¾“å‡ºè¾ƒçŸ­çš„ç¡®è®¤ä¿¡æ¯æˆ– JSON è§£æåçš„æ–‡æœ¬
                elif node_name in ["collect", "pay_flight", "pay_hotel", "check_weather", "select_flight", "select_hotel", "guide", "summary", "side_chat"]:
                    if msgs := output.get("messages"):
                        content = msgs[-1].content
                        if content:
                            yield create_event("message", {"content": content, "is_stream": False})

    except Exception as e:
        yield create_event("error", {"message": str(e)})
